{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intelligent-shirt",
   "metadata": {},
   "source": [
    "# LUSC : Cox-regression with elastic net regularization\n",
    "\n",
    "# Introduction\n",
    "\n",
    "The purpose of this workflow is to introduce the KM based feature selection followed by regularised cox regression analysis using ENET. \n",
    "\n",
    "# Preparing workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quick-sheet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:23.819253Z",
     "iopub.status.busy": "2023-01-26T10:50:23.817428Z",
     "iopub.status.idle": "2023-01-26T10:50:33.578770Z",
     "shell.execute_reply": "2023-01-26T10:50:33.577152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Loading required package: ggpubr\n",
      "\n",
      "\n",
      "Attaching package: ‘survminer’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:survival’:\n",
      "\n",
      "    myeloma\n",
      "\n",
      "\n",
      "Loading required package: Matrix\n",
      "\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:tidyr’:\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n",
      "\n",
      "Loaded glmnet 4.1-4\n",
      "\n",
      "========================================\n",
      "circlize version 0.4.14\n",
      "CRAN page: https://cran.r-project.org/package=circlize\n",
      "Github page: https://github.com/jokergoo/circlize\n",
      "Documentation: https://jokergoo.github.io/circlize_book/book/\n",
      "\n",
      "If you use it in published research, please cite:\n",
      "Gu, Z. circlize implements and enhances circular visualization\n",
      "  in R. Bioinformatics 2014.\n",
      "\n",
      "This message can be suppressed by:\n",
      "  suppressPackageStartupMessages(library(circlize))\n",
      "========================================\n",
      "\n",
      "\n",
      "Loading required package: grid\n",
      "\n",
      "========================================\n",
      "ComplexHeatmap version 2.10.0\n",
      "Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/\n",
      "Github page: https://github.com/jokergoo/ComplexHeatmap\n",
      "Documentation: http://jokergoo.github.io/ComplexHeatmap-reference\n",
      "\n",
      "If you use it in published research, please cite:\n",
      "Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional \n",
      "  genomic data. Bioinformatics 2016.\n",
      "\n",
      "The new InteractiveComplexHeatmap package can directly export static \n",
      "complex heatmaps into an interactive Shiny app with zero effort. Have a try!\n",
      "\n",
      "This message can be suppressed by:\n",
      "  suppressPackageStartupMessages(library(ComplexHeatmap))\n",
      "========================================\n",
      "\n",
      "\n",
      "Loading required package: prodlim\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "Loading required package: BiocGenerics\n",
      "\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    combine, intersect, setdiff, union\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which.max, which.min\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:Matrix’:\n",
      "\n",
      "    expand, unname\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    first, rename\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    expand\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "\n",
      "Loading required package: IRanges\n",
      "\n",
      "\n",
      "Attaching package: ‘IRanges’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    collapse, desc, slice\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    reduce\n",
      "\n",
      "\n",
      "Loading required package: GenomicRanges\n",
      "\n",
      "Loading required package: GenomeInfoDb\n",
      "\n",
      "Loading required package: SummarizedExperiment\n",
      "\n",
      "Loading required package: MatrixGenerics\n",
      "\n",
      "Loading required package: matrixStats\n",
      "\n",
      "\n",
      "Attaching package: ‘matrixStats’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    count\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘MatrixGenerics’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n",
      "    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n",
      "    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n",
      "    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n",
      "    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n",
      "    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n",
      "    colWeightedMeans, colWeightedMedians, colWeightedSds,\n",
      "    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n",
      "    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n",
      "    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n",
      "    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n",
      "    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n",
      "    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n",
      "    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n",
      "    rowWeightedSds, rowWeightedVars\n",
      "\n",
      "\n",
      "Loading required package: Biobase\n",
      "\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘Biobase’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:MatrixGenerics’:\n",
      "\n",
      "    rowMedians\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "setwd(\"/home/data/project_code/landstrom_core/prognostic_model_development/r/notebooks\")\n",
    "\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(survival)\n",
    "library(survminer)\n",
    "library(glmnet)\n",
    "library(WriteXLS)\n",
    "library(ggfortify)\n",
    "library(circlize)\n",
    "library(ComplexHeatmap)\n",
    "library(parallel)\n",
    "library(broom)\n",
    "library(survcomp)\n",
    "library(survivalROC)\n",
    "source(\"../getTCGAData.R\")\n",
    "source(\"../preprocessTCGAData.R\")\n",
    "source(\"../KM_analysis.R\")\n",
    "source(\"../Heatmaps.R\")\n",
    "source(\"../enet.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-palestine",
   "metadata": {},
   "source": [
    "# Setting up paths and clinical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respective-convergence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:33.608513Z",
     "iopub.status.busy": "2023-01-26T10:50:33.582027Z",
     "iopub.status.idle": "2023-01-26T10:50:33.618021Z",
     "shell.execute_reply": "2023-01-26T10:50:33.616673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the cancer type \n",
    "cancer.type = \"LUSC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-affiliation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:33.622022Z",
     "iopub.status.busy": "2023-01-26T10:50:33.620861Z",
     "iopub.status.idle": "2023-01-26T10:50:33.638920Z",
     "shell.execute_reply": "2023-01-26T10:50:33.637588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the table including the clinical features for each cancer type\n",
    "clin.feat.tb = read.table(\"/workstation/project_data/landstrom_core/clin_features_final.csv\", sep = \"\\t\", header = T)\n",
    "\n",
    "# Get Clinical variables\n",
    "clin.var = unlist(strsplit(clin.feat.tb$Features[clin.feat.tb$Ctype == cancer.type], split = \",\"))\n",
    "\n",
    "# Ensembl id mapping file \n",
    "ens.id.mapping = \"/home/organisms/Human/hg38/Homo_sapiens.GRCh38_March2022/ENSEMBLE_to_SYMBOL.csv\"\n",
    "\n",
    "# Output dir \n",
    "out.dir.data = file.path(\"/workstation/project_data/landstrom_core/rdata/manuscript_work/\", cancer.type)\n",
    "dir.create(out.dir.data, recursive = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statistical-disposition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:33.642769Z",
     "iopub.status.busy": "2023-01-26T10:50:33.641617Z",
     "iopub.status.idle": "2023-01-26T10:50:33.655287Z",
     "shell.execute_reply": "2023-01-26T10:50:33.653980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Age'</li><li>'Gender'</li><li>'Tumor.stage'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Age'\n",
       "\\item 'Gender'\n",
       "\\item 'Tumor.stage'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Age'\n",
       "2. 'Gender'\n",
       "3. 'Tumor.stage'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Age\"         \"Gender\"      \"Tumor.stage\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clin.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-orbit",
   "metadata": {},
   "source": [
    "# 1. Read in data \n",
    "\n",
    "Read in data using dedicated functions. Only parameter is the cancer code (Abbreviation) which can be \n",
    "found [here](https://gdc.cancer.gov/resources-tcga-users/tcga-code-tables/tcga-study-abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-geneva",
   "metadata": {},
   "source": [
    "Read in copy-number data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-thomas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:33.659391Z",
     "iopub.status.busy": "2023-01-26T10:50:33.658247Z",
     "iopub.status.idle": "2023-01-26T10:50:40.224417Z",
     "shell.execute_reply": "2023-01-26T10:50:40.222909Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.cn = getTCGACopyNumberData(cancer.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-coordinate",
   "metadata": {},
   "source": [
    "Read in gene expression data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worst-reserve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:40.228847Z",
     "iopub.status.busy": "2023-01-26T10:50:40.227671Z",
     "iopub.status.idle": "2023-01-26T10:50:55.128469Z",
     "shell.execute_reply": "2023-01-26T10:50:55.126849Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.expr = getTCGAExpressionData(cancer.type, annotation.file = ens.id.mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-pasta",
   "metadata": {},
   "source": [
    "Read in clinical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sitting-rachel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:55.132971Z",
     "iopub.status.busy": "2023-01-26T10:50:55.131766Z",
     "iopub.status.idle": "2023-01-26T10:50:55.399527Z",
     "shell.execute_reply": "2023-01-26T10:50:55.398004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get cancer specific clinical data \n",
    "tcga.clin = getClinData(cancer.type)\n",
    "\n",
    "# Get the end point related clinical data \n",
    "tcga.endpoints = getClinEndpointData(cancer.type) %>% dplyr::select(bcr_patient_barcode, OS, OS.time, DSS, DSS.time, DFI, DFI.time, PFI, PFI.time)\n",
    "\n",
    "# Merge end point data to clinical data \n",
    "tcga.clin = dplyr::left_join(tcga.clin, tcga.endpoints, by = \"bcr_patient_barcode\")\n",
    "\n",
    "write.csv(tcga.clin, file.path(out.dir.data, \"clinical_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-overhead",
   "metadata": {},
   "source": [
    "# 2. Preprocessing of the data\n",
    "\n",
    "## 2.1 Copy number data\n",
    "\n",
    "Keep only primary tumor samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uniform-simulation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:55.403846Z",
     "iopub.status.busy": "2023-01-26T10:50:55.402681Z",
     "iopub.status.idle": "2023-01-26T10:50:55.483243Z",
     "shell.execute_reply": "2023-01-26T10:50:55.481912Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.cn = selectPrimaryT(tcga.cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-tournament",
   "metadata": {},
   "source": [
    "Drop out duplicate samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "racial-segment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:55.487286Z",
     "iopub.status.busy": "2023-01-26T10:50:55.486135Z",
     "iopub.status.idle": "2023-01-26T10:50:55.612776Z",
     "shell.execute_reply": "2023-01-26T10:50:55.611443Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.cn = dropDuplicateSamples(tcga.cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-bubble",
   "metadata": {},
   "source": [
    "Prepare data matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ruled-heavy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:55.616791Z",
     "iopub.status.busy": "2023-01-26T10:50:55.615644Z",
     "iopub.status.idle": "2023-01-26T10:50:59.231400Z",
     "shell.execute_reply": "2023-01-26T10:50:59.229802Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.cn.datamat = prepareDataMatrix(tcga.cn)\n",
    "saveRDS(tcga.cn.datamat, file = file.path(out.dir.data, \"copy_number_status.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-placement",
   "metadata": {},
   "source": [
    "## 2.2 Gene expression data \n",
    "\n",
    "Variance stabilizing transformation of the data was performed as suggested by the DESeq2 developers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternate-fault",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:50:59.235765Z",
     "iopub.status.busy": "2023-01-26T10:50:59.234562Z",
     "iopub.status.idle": "2023-01-26T10:51:25.501988Z",
     "shell.execute_reply": "2023-01-26T10:51:25.500409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting counts to integer mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the raw data for future purposes \n",
    "tcga.expr$Raw = tcga.expr$Data\n",
    "\n",
    "# Perform variance stabilising transformation (VST)\n",
    "tcga.expr$Data = performVST(tcga.expr$Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-airline",
   "metadata": {},
   "source": [
    "Keep only the primary tumors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "minus-malawi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:51:25.506919Z",
     "iopub.status.busy": "2023-01-26T10:51:25.505699Z",
     "iopub.status.idle": "2023-01-26T10:51:25.851989Z",
     "shell.execute_reply": "2023-01-26T10:51:25.850337Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.expr = selectPrimaryT(tcga.expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-brazil",
   "metadata": {},
   "source": [
    "Drop duplicate samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demanding-breed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:51:25.856418Z",
     "iopub.status.busy": "2023-01-26T10:51:25.855235Z",
     "iopub.status.idle": "2023-01-26T10:51:26.903635Z",
     "shell.execute_reply": "2023-01-26T10:51:26.901971Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.expr = dropDuplicateSamples(tcga.expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-growing",
   "metadata": {},
   "source": [
    "Finally we prepare a data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loose-fishing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:51:26.908015Z",
     "iopub.status.busy": "2023-01-26T10:51:26.906846Z",
     "iopub.status.idle": "2023-01-26T10:52:12.895069Z",
     "shell.execute_reply": "2023-01-26T10:52:12.893107Z"
    }
   },
   "outputs": [],
   "source": [
    "tcga.expr.raw.datamat = prepareDataMatrixRaw(tcga.expr)\n",
    "tcga.expr.datamat = prepareDataMatrix(tcga.expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blind-kitty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:52:12.902238Z",
     "iopub.status.busy": "2023-01-26T10:52:12.900866Z",
     "iopub.status.idle": "2023-01-26T10:52:28.777733Z",
     "shell.execute_reply": "2023-01-26T10:52:28.775833Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "saveRDS(tcga.expr.raw.datamat, \n",
    "        file = file.path(out.dir.data, \"raw_expressions.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-seven",
   "metadata": {},
   "source": [
    "## 2.3 Merging all data \n",
    "\n",
    "Merge all the different data types together. Takes the clinical data as \n",
    "a separate argument and the sequencing data as a list of data matrices.\n",
    "Suffixes are added based on user given vector which correspond to the \n",
    "order in which datamatrices are in the data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thermal-affiliate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:52:28.782917Z",
     "iopub.status.busy": "2023-01-26T10:52:28.781516Z",
     "iopub.status.idle": "2023-01-26T10:53:23.737584Z",
     "shell.execute_reply": "2023-01-26T10:53:23.735910Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tcga.dataset = mergeTCGAdata(clin.data = tcga.clin,\n",
    "                                  data = list(tcga.cn.datamat, \n",
    "                                              tcga.expr.datamat), \n",
    "                                  data.suffixes = c(\"cn\",\"exp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "marine-auditor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:23.744542Z",
     "iopub.status.busy": "2023-01-26T10:53:23.743336Z",
     "iopub.status.idle": "2023-01-26T10:53:33.212993Z",
     "shell.execute_reply": "2023-01-26T10:53:33.211361Z"
    }
   },
   "outputs": [],
   "source": [
    "saveRDS(tcga.dataset, file = file.path(out.dir.data, \"tcga.dataset.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-society",
   "metadata": {},
   "source": [
    "# 3. KM based univariate feature selection\n",
    "\n",
    "We will now perform the univariate feature selection which is the first phase of \n",
    "the actual analysis. The idea is to prefilter some features which have no predictive \n",
    "power regarding survival. We will select one clinical end point which seems to carry \n",
    "most events to maximise the statistical power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-accordance",
   "metadata": {},
   "source": [
    "## 3.1 Loading data and selection of variables \n",
    "\n",
    "Load the dataset if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "light-paint",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:33.217518Z",
     "iopub.status.busy": "2023-01-26T10:53:33.216346Z",
     "iopub.status.idle": "2023-01-26T10:53:35.992615Z",
     "shell.execute_reply": "2023-01-26T10:53:35.991120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the preprocessed dataset if continued \n",
    "tcga.dataset = readRDS(file.path(out.dir.data, \"tcga.dataset.rds\"))\n",
    "\n",
    "# Raw expression data \n",
    "tcga.expr.raw.datamat = readRDS(file.path(out.dir.data, \"raw_expressions.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-professional",
   "metadata": {},
   "source": [
    "Define and create output directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demanding-programmer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:35.996869Z",
     "iopub.status.busy": "2023-01-26T10:53:35.995697Z",
     "iopub.status.idle": "2023-01-26T10:53:36.010572Z",
     "shell.execute_reply": "2023-01-26T10:53:36.009265Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define and create the root directory for results \n",
    "dir.res.root = file.path(\"/workstation/project_results/landstrom_core/prognostic_model_development/models_by_cancer_type/\", cancer.type)\n",
    "dir.create(dir.res.root, recursive = T)\n",
    "\n",
    "# Define and create the results for the KM analysis \n",
    "dir.res.km = file.path(dir.res.root, \"Kaplan_Meier_plots\")\n",
    "dir.create(dir.res.km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-accounting",
   "metadata": {},
   "source": [
    "Read in the gene list of interest including the customer genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "worst-boutique",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.014546Z",
     "iopub.status.busy": "2023-01-26T10:53:36.013413Z",
     "iopub.status.idle": "2023-01-26T10:53:36.024850Z",
     "shell.execute_reply": "2023-01-26T10:53:36.023544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gene list  \n",
    "gene.list.file = read.table(\"/workstation/project_data/landstrom_core/Customer_genes.tsv\", \n",
    "                            sep = \"\\t\", header = F)\n",
    "gene.list = gene.list.file$V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-reconstruction",
   "metadata": {},
   "source": [
    "Tabulate the number of events. Value 0 means sensored and value 1 an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prime-victor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.028794Z",
     "iopub.status.busy": "2023-01-26T10:53:36.027667Z",
     "iopub.status.idle": "2023-01-26T10:53:36.404119Z",
     "shell.execute_reply": "2023-01-26T10:53:36.402662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'name'. You can override using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "clinical.end.point.stats = tcga.dataset %>% \n",
    "                                   dplyr::select(c(\"OS.clin\",\"DSS.clin\",\"DFI.clin\",\"PFI.clin\")) %>%\n",
    "                                   pivot_longer(everything()) %>%\n",
    "                                   mutate(value = factor(value)) %>%\n",
    "                                   group_by(name, value) %>%\n",
    "                                   summarise(N = n()) %>% \n",
    "                                   pivot_wider(names_from =  value,\n",
    "                                               values_from = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "voluntary-belfast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.408215Z",
     "iopub.status.busy": "2023-01-26T10:53:36.407058Z",
     "iopub.status.idle": "2023-01-26T10:53:36.426156Z",
     "shell.execute_reply": "2023-01-26T10:53:36.424870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A grouped_df: 4 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>name</th><th scope=col>0</th><th scope=col>1</th><th scope=col>NA</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>DFI.clin</td><td>241</td><td> 63</td><td>200</td></tr>\n",
       "\t<tr><td>DSS.clin</td><td>361</td><td> 91</td><td> 52</td></tr>\n",
       "\t<tr><td>OS.clin </td><td>285</td><td>219</td><td> NA</td></tr>\n",
       "\t<tr><td>PFI.clin</td><td>355</td><td>149</td><td> NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A grouped\\_df: 4 × 4\n",
       "\\begin{tabular}{llll}\n",
       " name & 0 & 1 & NA\\\\\n",
       " <chr> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t DFI.clin & 241 &  63 & 200\\\\\n",
       "\t DSS.clin & 361 &  91 &  52\\\\\n",
       "\t OS.clin  & 285 & 219 &  NA\\\\\n",
       "\t PFI.clin & 355 & 149 &  NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A grouped_df: 4 × 4\n",
       "\n",
       "| name &lt;chr&gt; | 0 &lt;int&gt; | 1 &lt;int&gt; | NA &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| DFI.clin | 241 |  63 | 200 |\n",
       "| DSS.clin | 361 |  91 |  52 |\n",
       "| OS.clin  | 285 | 219 |  NA |\n",
       "| PFI.clin | 355 | 149 |  NA |\n",
       "\n"
      ],
      "text/plain": [
       "  name     0   1   NA \n",
       "1 DFI.clin 241  63 200\n",
       "2 DSS.clin 361  91  52\n",
       "3 OS.clin  285 219  NA\n",
       "4 PFI.clin 355 149  NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clinical.end.point.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-penguin",
   "metadata": {},
   "source": [
    "## 3.2 Splitting dataset into training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-membership",
   "metadata": {},
   "source": [
    "Here we change the original workflow such that we run the analysis for all clinical end points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "religious-voice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.430289Z",
     "iopub.status.busy": "2023-01-26T10:53:36.429154Z",
     "iopub.status.idle": "2023-01-26T10:53:36.442344Z",
     "shell.execute_reply": "2023-01-26T10:53:36.441024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we store all the training and validation splits \n",
    "train_and_validation_ls = list()\n",
    "\n",
    "# Variables selected \n",
    "variables_selected_ls = list()\n",
    "\n",
    "# Number of samples in training and validation cohorts \n",
    "nsamples_step1_ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "polyphonic-october",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.446238Z",
     "iopub.status.busy": "2023-01-26T10:53:36.445097Z",
     "iopub.status.idle": "2023-01-26T10:53:36.603629Z",
     "shell.execute_reply": "2023-01-26T10:53:36.602187Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 494 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 442 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 299 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 495 cases out of 504 cases\"\n"
     ]
    }
   ],
   "source": [
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "\n",
    "    # Selected variables \n",
    "    variables.selected = selectVariables(clinical.endpoint = end.point, \n",
    "                                     gene.list = gene.list, \n",
    "                                     data.suffixes = c(\"cn\",\"exp\"))\n",
    "    variables_selected_ls[[end.point]] = variables.selected\n",
    "    \n",
    "    #Data set is split randomly into training and validation sets. Only complete cases \n",
    "    # are selected.\n",
    "    train_and_validation = splitCases(data = tcga.dataset, \n",
    "                                  split = 0.75, \n",
    "                                  only.complete = T,\n",
    "                                  variables = variables.selected, \n",
    "                                  seed = 42)\n",
    "    \n",
    "    # Update list\n",
    "    train_and_validation_ls[[end.point]] = train_and_validation \n",
    "    \n",
    "    \n",
    "    # Store number of  \n",
    "    nsamples.step1 = c(nrow(train_and_validation$train), nrow(train_and_validation$validation))\n",
    "    names(nsamples.step1) = c(\"ntrain.step1\", \"nvalid.step1\")\n",
    "    nsamples_step1_ls[[end.point]] = nsamples.step1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-building",
   "metadata": {},
   "source": [
    "## 3.3 Filtering step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-litigation",
   "metadata": {},
   "source": [
    "### 3.3.1 Calculate relevant statistics for the training set. \n",
    "\n",
    "We will calculate the following statistics for expression features based on the raw expression data : \n",
    "1. The fraction of individuals expressing the feature  \n",
    "2. Median expression of the feature\n",
    "3. Variance of the feature\n",
    "\n",
    "We will calculate the following statistics for copy number features \n",
    "1. Fraction of individuals with amplification \n",
    "2. Fraction of individuals with deletion\n",
    "3. Fraction of individuals with missing CN status \n",
    "4. Max value out of the fraction of individuals with amplification and deletions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bulgarian-yellow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:36.608057Z",
     "iopub.status.busy": "2023-01-26T10:53:36.606880Z",
     "iopub.status.idle": "2023-01-26T10:53:37.190832Z",
     "shell.execute_reply": "2023-01-26T10:53:37.189279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store summary statistics \n",
    "summary.stats.ls = list()\n",
    "\n",
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    exp.summary.training = prepSummaryExp(x = train_and_validation$train, \n",
    "                                      raw.data = tcga.expr.raw.datamat,\n",
    "                                      variables = variables.selected, type = \"exp\")\n",
    "\n",
    "    cn.summary.training = prepSummaryCN(train_and_validation$train, variables = variables.selected, type = \"cn\")\n",
    "    \n",
    "    summary.stats.ls[[end.point]] = list(\"exp.summary.training\" = exp.summary.training,\n",
    "                                         \"cn.summary.training\" = cn.summary.training)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-score",
   "metadata": {},
   "source": [
    "### 3.3.2 Filter based on the calculated statistics\n",
    "\n",
    "We will set the filtering thresholds as follows : \n",
    "\n",
    "Expression features : \n",
    "\n",
    "1. Median expression must be greater than 20\n",
    "2. Fraction of individuals expressing feature must be greater than > 0.25\n",
    "\n",
    "CN features \n",
    "\n",
    "1. Maximum Fraction of individuals carrying either deletion or amplification must be at least 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "liberal-throat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:37.195201Z",
     "iopub.status.busy": "2023-01-26T10:53:37.194026Z",
     "iopub.status.idle": "2023-01-26T10:53:37.297833Z",
     "shell.execute_reply": "2023-01-26T10:53:37.296466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store filtered variables \n",
    "variables.selected.filtered.ls = list()\n",
    "\n",
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "\n",
    "    exp.features.keep = summary.stats.ls[[end.point]]$exp.summary.training %>% \n",
    "                          filter(`Median expression` > 20, \n",
    "                                 `Fraction of zero expression` < 0.75)\n",
    "\n",
    "    cn.features.keep = summary.stats.ls[[end.point]]$cn.summary.training %>% \n",
    "                          filter(`Maximum fraction of aberrations` > 0.15) \n",
    "\n",
    "    # Update the summary tables \n",
    "    summary.stats.ls[[end.point]]$exp.summary.training$Selected = ifelse(summary.stats.ls[[end.point]]$exp.summary.training$name %in% exp.features.keep$name, \"Yes\", \"No\")\n",
    "    summary.stats.ls[[end.point]]$cn.summary.training$Selected = ifelse(summary.stats.ls[[end.point]]$cn.summary.training$name %in% cn.features.keep$name, \"Yes\", \"No\")\n",
    "\n",
    "    # Collect the variables into vector \n",
    "    variables.selected.filtered.ls[[end.point]] = filterFeatures(variables_selected_ls[[end.point]], exp.features.keep$name, type = \"exp\")\n",
    "    variables.selected.filtered.ls[[end.point]]= filterFeatures(variables_selected_ls[[end.point]], cn.features.keep$name, type = \"cn\")\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-concentration",
   "metadata": {},
   "source": [
    "Final list of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-algorithm",
   "metadata": {},
   "source": [
    "## 3.4 Prepare univariate KM plots and logrank tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "applicable-nicholas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:37.302146Z",
     "iopub.status.busy": "2023-01-26T10:53:37.300997Z",
     "iopub.status.idle": "2023-01-26T10:54:52.312335Z",
     "shell.execute_reply": "2023-01-26T10:54:52.310701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "NULL\n",
      "NULL\n"
     ]
    }
   ],
   "source": [
    "# Store the KM tables \n",
    "km.pvalue.table.ls = list()\n",
    "\n",
    "# Store the significant features \n",
    "significant.features.ls = list()\n",
    "\n",
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "\n",
    "    # Create dir for plots \n",
    "    dir.create(file.path(dir.res.km, end.point))\n",
    "    \n",
    "    if (nrow(train_and_validation_ls[[end.point]]$train) > 0){\n",
    "    \n",
    "        # Run univariate KM\n",
    "        km.pvalue.table = runUnivariateKM(input.data = train_and_validation_ls[[end.point]], \n",
    "                                  variables = variables.selected.filtered.ls[[end.point]],\n",
    "                                  clinical.endpoint = end.point,\n",
    "                                  out.dir = file.path(dir.res.km, end.point),\n",
    "                                  plots = T)\n",
    "    \n",
    "    \n",
    "        # Sort the results based on the training p-value and write the results to output\n",
    "        km.pvalue.table = km.pvalue.table %>% dplyr::arrange(pvalues.training)\n",
    "        km.pvalue.table$Selected = ifelse(km.pvalue.table$pvalues.training < 0.05, \"Yes\", \"No\") \n",
    "        write.csv(km.pvalue.table, file.path(dir.res.km, paste0(end.point, \"_LogRank_pvalues.csv\")))\n",
    "    \n",
    "        km.pvalue.table.ls[[end.point]] = km.pvalue.table\n",
    "    \n",
    "        # Extract the significant features \n",
    "        significant.features = getSignificantFeatures(km.pvalue.table, pvalue.thresh = 0.05)\n",
    "\n",
    "        # Store \n",
    "        significant.features.ls[[end.point]] = significant.features\n",
    "        \n",
    "    } else {\n",
    "        significant.features.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-adjustment",
   "metadata": {},
   "source": [
    "# 4 Penalised cox regression without clinical variables \n",
    "\n",
    "Define path to output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greek-combine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.321310Z",
     "iopub.status.busy": "2023-01-26T10:54:52.320029Z",
     "iopub.status.idle": "2023-01-26T10:54:52.333150Z",
     "shell.execute_reply": "2023-01-26T10:54:52.331716Z"
    }
   },
   "outputs": [],
   "source": [
    "dir.res.pcox = file.path(dir.res.root, \"Penalized_Cox_risk_prediction/customer_features/Without_clinical_features\")\n",
    "dir.create(dir.res.pcox, recursive = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faced-analysis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.337338Z",
     "iopub.status.busy": "2023-01-26T10:54:52.336124Z",
     "iopub.status.idle": "2023-01-26T10:54:52.346547Z",
     "shell.execute_reply": "2023-01-26T10:54:52.345141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for fixing variable names \n",
    "fixVarNames = function(x){\n",
    "    if (str_detect(x, \"Gender\")) {\n",
    "        return(\"Gender\")\n",
    "    } else if (str_detect(x, \"Tumor.stage\")){\n",
    "        return(\"Tumor.stage\")\n",
    "    } else if (str_detect(x,\".cn\")){\n",
    "        return(str_extract(x, \"\\\\w+.cn\"))\n",
    "    } else if (str_detect(x, \"Gleason.group\")){ \n",
    "        return(\"Gleason.group\")\n",
    "    } else {\n",
    "        return(x)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-rendering",
   "metadata": {},
   "source": [
    "## 4.1 Splitting dataset into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "awful-crack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.350686Z",
     "iopub.status.busy": "2023-01-26T10:54:52.349464Z",
     "iopub.status.idle": "2023-01-26T10:54:52.361425Z",
     "shell.execute_reply": "2023-01-26T10:54:52.360050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we store all the training and validation splits \n",
    "train_and_validation_ls = list()\n",
    "\n",
    "# Number of samples in training and validation cohorts \n",
    "nsamples_step2_ls_no_clin = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cordless-mobile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.365497Z",
     "iopub.status.busy": "2023-01-26T10:54:52.364284Z",
     "iopub.status.idle": "2023-01-26T10:54:52.449025Z",
     "shell.execute_reply": "2023-01-26T10:54:52.447567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 495 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 496 cases out of 504 cases\"\n"
     ]
    }
   ],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    # We will first combine the significant.features with the outcome variables\n",
    "    # Final list of features \n",
    "    feature.ls = c(paste0(end.point, c(\".clin\",\".time.clin\")), significant.features.ls[[end.point]])\n",
    "    \n",
    "    if (is.null(significant.features.ls[[end.point]]) == F) {\n",
    "    \n",
    "        # Now we split the dataset into training and validation cohorts exactly as before.\n",
    "        train_and_validation = splitCases(data = tcga.dataset, \n",
    "                                  split = 0.75, \n",
    "                                  only.complete = T,\n",
    "                                  variables = feature.ls,\n",
    "                                  seed = 42)\n",
    "    \n",
    "        # Store \n",
    "        train_and_validation_ls[[end.point]] = train_and_validation\n",
    "    \n",
    "        # Store the number of samples       \n",
    "        nsamples.step2 = c(nrow(train_and_validation$train), nrow(train_and_validation$validation))\n",
    "    }    \n",
    "    else {\n",
    "    \n",
    "        # If there are now significant features store NULL\n",
    "        \n",
    "        # Store \n",
    "        train_and_validation_ls[[end.point]] = NULL\n",
    "        nsamples.step2 = c(NA, NA)\n",
    "    }\n",
    "        \n",
    "    names(nsamples.step2) = c(\"ntrain.step2\", \"nvalid.step2\")\n",
    "    nsamples_step2_ls_no_clin[[end.point]] = nsamples.step2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-resolution",
   "metadata": {},
   "source": [
    "## 4.2 Find the optimal lambda \n",
    "\n",
    "Use 10-fold cross-validation (CV) for the Cox model for different values of lamda. C-index will be use to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "organic-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.453370Z",
     "iopub.status.busy": "2023-01-26T10:54:52.452146Z",
     "iopub.status.idle": "2023-01-26T10:54:52.466727Z",
     "shell.execute_reply": "2023-01-26T10:54:52.465317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store significant features \n",
    "rcox.res.no.clin.ls = list()\n",
    "\n",
    "# Store model matrices\n",
    "model.matrices.ls = list()\n",
    "\n",
    "# Store the fitted models for prediction \n",
    "pcox.fit.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vital-vertex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:52.470865Z",
     "iopub.status.busy": "2023-01-26T10:54:52.469642Z",
     "iopub.status.idle": "2023-01-26T10:54:54.132495Z",
     "shell.execute_reply": "2023-01-26T10:54:54.130282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    # Check the number of features\n",
    "    # Regulariation cannot be run if there is only one feature\n",
    "    num.feat = ncol(train_and_validation_ls[[end.point]]$train) - 2\n",
    "    \n",
    "    if (is.null(train_and_validation_ls[[end.point]]$train) == F){\n",
    "        if (num.feat > 1) {\n",
    "    \n",
    "            # Genereate model matrix \n",
    "            model.matrices = generateModelMatrices(train_and_validation_ls[[end.point]]$train, \n",
    "                             train_and_validation_ls[[end.point]]$validation, \n",
    "                             clinical.endpoint = end.point)\n",
    "        \n",
    "            model.matrices.ls[[end.point]] = model.matrices\n",
    "    \n",
    "            # Create output dir \n",
    "            dir.create(file.path(dir.res.pcox, end.point))\n",
    "    \n",
    "            # Find optimal lambda (hyperparameter for elastic net)\n",
    "            pcox.fit = findOptimalLambda(x = model.matrices$x.train.mat, \n",
    "                             y = model.matrices$y.train,\n",
    "                             out.dir = file.path(dir.res.pcox, end.point))\n",
    "        \n",
    "            pcox.fit.ls[[end.point]] = pcox.fit\n",
    "    \n",
    "            # Write the final features included in the model to a file \n",
    "            WriteXLS(pcox.fit$active.k.vals, \n",
    "             file.path(dir.res.pcox, end.point ,\"Active_covariates_in_lambda.min_model.xlsx\"), \n",
    "             BoldHeaderRow = T,\n",
    "             row.names = T)\n",
    "    \n",
    "            # Final significant features \n",
    "            rcox.res.no.clin = pcox.fit$active.k.vals %>% tibble::rownames_to_column(\"Feature\")\n",
    "            rcox.res.no.clin.ls[[end.point]] = rcox.res.no.clin  \n",
    "        } else {\n",
    "            # If no significant features from earlier steps for the clin. end point then store null\n",
    "            model.matrices.ls[[end.point]] = NULL\n",
    "            pcox.fit.ls[[end.point]] = NULL\n",
    "            rcox.res.no.clin.ls[[end.point]] = NULL\n",
    "        }\n",
    "\n",
    "    } else {\n",
    "        # If no significant features from earlier steps for the clin. end point then store null\n",
    "        model.matrices.ls[[end.point]] = NULL\n",
    "        pcox.fit.ls[[end.point]] = NULL\n",
    "        rcox.res.no.clin.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-virtue",
   "metadata": {},
   "source": [
    "## 4.3 Make predictions using the cross-validated model and heatmaps for visualisation\n",
    "\n",
    "## 4.3.1 Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "virtual-depth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:54.137892Z",
     "iopub.status.busy": "2023-01-26T10:54:54.136348Z",
     "iopub.status.idle": "2023-01-26T10:54:54.150598Z",
     "shell.execute_reply": "2023-01-26T10:54:54.148997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.train.by.risk.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "creative-theology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:54.155449Z",
     "iopub.status.busy": "2023-01-26T10:54:54.153968Z",
     "iopub.status.idle": "2023-01-26T10:54:56.173181Z",
     "shell.execute_reply": "2023-01-26T10:54:56.171552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    if (!is.null(pcox.fit.ls[[end.point]])) {\n",
    "    \n",
    "        # Predictions for the training set\n",
    "        pred.train <- predict(pcox.fit.ls[[end.point]]$model, \n",
    "                      newx = model.matrices.ls[[end.point]]$x.train.mat, \n",
    "                      s = \"lambda.min\", \n",
    "                      type = \"response\")\n",
    "\n",
    "        # Fitted relative risk\n",
    "        rel.risk <- pred.train[,1] \n",
    "\n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- as.data.frame(as.matrix(model.matrices.ls[[end.point]]$y.train))\n",
    "        \n",
    "        \n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.train.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                        rel.risk = rel.risk)\n",
    "        \n",
    "        if (!is.null(KM.train.by.risk)) {\n",
    "        \n",
    "            # Store\n",
    "            KM.train.by.risk.ls[[end.point]] =  KM.train.by.risk$table\n",
    "    \n",
    "            # Store the KM plot\n",
    "            pdf(file.path(dir.res.pcox, end.point ,\"glmnet_K-M_plot_with_training_data.pdf\"), \n",
    "                width = 15, height = 12, onefile = F)\n",
    "            print(KM.train.by.risk$Plot)\n",
    "            dev.off()\n",
    "    \n",
    "            # Heatmap preparation         \n",
    "    \n",
    "            # Variables to be selected \n",
    "            # Because Gender has been changed to a dummy variable its name has been changed\n",
    "            variables.selected = map_chr(rcox.res.no.clin.ls[[end.point]]$Feature, fixVarNames)\n",
    "    \n",
    "            # Get all input variables\n",
    "            heatmap.input.train = model.matrices.ls[[end.point]]$x.train %>% dplyr::select(all_of(variables.selected))\n",
    "    \n",
    "            # Heatmap of training data predictions\n",
    "            hmap.train <- prepareHeatmap(heatmap.input.train, y.data, pred.train, file.path(dir.res.pcox, end.point), \"glmnet_training\", row.height = 8) \n",
    "        \n",
    "        } else {\n",
    "            KM.train.by.risk.ls[[end.point]] = NULL\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        KM.train.by.risk.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-municipality",
   "metadata": {},
   "source": [
    "## 4.3.2 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "given-laser",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:56.177746Z",
     "iopub.status.busy": "2023-01-26T10:54:56.176489Z",
     "iopub.status.idle": "2023-01-26T10:54:56.187427Z",
     "shell.execute_reply": "2023-01-26T10:54:56.186022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.valid.by.risk.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "serious-acting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:56.191609Z",
     "iopub.status.busy": "2023-01-26T10:54:56.190384Z",
     "iopub.status.idle": "2023-01-26T10:54:59.886109Z",
     "shell.execute_reply": "2023-01-26T10:54:59.884464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    if (!is.null(pcox.fit.ls[[end.point]])) {\n",
    "    \n",
    "        # Predictions for the training set\n",
    "        pred.valid <- predict(pcox.fit.ls[[end.point]]$model, \n",
    "                      newx = model.matrices.ls[[end.point]]$x.valid.mat, \n",
    "                      s = \"lambda.min\", \n",
    "                      type = \"response\")\n",
    "\n",
    "        # Fitted relative risk\n",
    "        rel.risk <- pred.valid[,1] \n",
    "\n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- as.data.frame(as.matrix(model.matrices.ls[[end.point]]$y.valid))\n",
    "\n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.valid.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                        rel.risk = rel.risk)\n",
    "        \n",
    "        if (!is.null(KM.train.by.risk)) {\n",
    "        \n",
    "            # Store\n",
    "            KM.valid.by.risk.ls[[end.point]] =  KM.valid.by.risk$table\n",
    "    \n",
    "            # Store the KM plot\n",
    "            pdf(file.path(dir.res.pcox, end.point ,\"glmnet_K-M_plot_with_validation_data.pdf\"), \n",
    "            width = 15, height = 12, onefile = F)\n",
    "            print(KM.valid.by.risk$Plot)\n",
    "            dev.off()\n",
    "    \n",
    "            # Heatmap preparation \n",
    "    \n",
    "            # Variables to be selected \n",
    "            variables.selected = map_chr(rcox.res.no.clin.ls[[end.point]]$Feature, fixVarNames) \n",
    "    \n",
    "            # Get all input variables\n",
    "            heatmap.input.valid = model.matrices.ls[[end.point]]$x.valid %>% dplyr::select(all_of(variables.selected))\n",
    "    \n",
    "            # Heatmap of training data predictions\n",
    "            hmap.valid <- prepareHeatmap(heatmap.input.valid, y.data, pred.valid, file.path(dir.res.pcox, end.point), \"glmnet_validation\", row.height = 8)  \n",
    "        \n",
    "        } else {\n",
    "            KM.valid.by.risk.ls[[end.point]] = NULL\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        KM.valid.by.risk.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-advice",
   "metadata": {},
   "source": [
    "Merge the two result tables into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "standard-landscape",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:59.890668Z",
     "iopub.status.busy": "2023-01-26T10:54:59.889401Z",
     "iopub.status.idle": "2023-01-26T10:54:59.902142Z",
     "shell.execute_reply": "2023-01-26T10:54:59.900757Z"
    }
   },
   "outputs": [],
   "source": [
    "KM.by.risk.no.clin.train = bind_rows(KM.train.by.risk.ls, .id = \"End point\")\n",
    "KM.by.risk.no.clin.valid = bind_rows(KM.valid.by.risk.ls, .id = \"End point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "chinese-salem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:59.906188Z",
     "iopub.status.busy": "2023-01-26T10:54:59.904994Z",
     "iopub.status.idle": "2023-01-26T10:54:59.917788Z",
     "shell.execute_reply": "2023-01-26T10:54:59.916357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store final resilts\n",
    "write.csv(KM.by.risk.no.clin.train, file.path(dir.res.pcox, \"Final_evaluation_results_training.csv\"), row.names = F)\n",
    "write.csv(KM.by.risk.no.clin.valid, file.path(dir.res.pcox, \"Final_evaluation_results_validation.csv\"),row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-greece",
   "metadata": {},
   "source": [
    "# 5 Penalised cox regression with clinical variables\n",
    "\n",
    "In the case of LUSC we will use Age and Gender.\n",
    "\n",
    "Define path to output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "surface-occurrence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:59.921925Z",
     "iopub.status.busy": "2023-01-26T10:54:59.920718Z",
     "iopub.status.idle": "2023-01-26T10:54:59.932004Z",
     "shell.execute_reply": "2023-01-26T10:54:59.930586Z"
    }
   },
   "outputs": [],
   "source": [
    "dir.res.pcox = file.path(dir.res.root, \"Penalized_Cox_risk_prediction/customer_features/With_clinical_features\")\n",
    "dir.create(dir.res.pcox, recursive = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-release",
   "metadata": {},
   "source": [
    "## 5.1 Preprocess clinical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "removed-october",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:59.936207Z",
     "iopub.status.busy": "2023-01-26T10:54:59.935023Z",
     "iopub.status.idle": "2023-01-26T10:54:59.945468Z",
     "shell.execute_reply": "2023-01-26T10:54:59.944059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function for adding the clinical variables \n",
    "addClinVar = function(data, clin.var) {\n",
    "    if (\"Age\" %in% clin.var) {\n",
    "        data$Age <- data$age_at_diagnosis.clin\n",
    "    } \n",
    "    if (\"Tumor.stage\" %in% clin.var){\n",
    "        data$Tumor.stage = factor(map_chr(data$ajcc_pathologic_stage.clin, reformatTumorStage))\n",
    "    }\n",
    "    if (\"Gender\" %in% clin.var){\n",
    "        data$Gender <- factor(data$gender.clin)    \n",
    "    } \n",
    "    if (\"Gleason.group\" %in% clin.var) {\n",
    "        \n",
    "        # Determine the Gleason group \n",
    "        data$Gleason.group = map2_chr(data$primary_gleason_grade.clin, \n",
    "                                           data$secondary_gleason_grade.clin, \n",
    "                                           determineGleasonGroup)\n",
    "\n",
    "        # Set up the factor levels \n",
    "        data$Gleason.group = factor(data$Gleason.group, \n",
    "                                    levels = c(\"Gleason group 1\", \"Gleason group 2\"))\n",
    "    }\n",
    "    return(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "least-algeria",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:59.949419Z",
     "iopub.status.busy": "2023-01-26T10:54:59.948235Z",
     "iopub.status.idle": "2023-01-26T10:55:00.163710Z",
     "shell.execute_reply": "2023-01-26T10:55:00.161523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add clinical variables to dataset\n",
    "tcga.dataset = addClinVar(tcga.dataset, clin.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-fight",
   "metadata": {},
   "source": [
    "## 5.2 Splitting dataset into training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-nomination",
   "metadata": {},
   "source": [
    "Generate the final feature ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fleet-electronics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:00.168395Z",
     "iopub.status.busy": "2023-01-26T10:55:00.167129Z",
     "iopub.status.idle": "2023-01-26T10:55:00.181240Z",
     "shell.execute_reply": "2023-01-26T10:55:00.179854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we store all the training and validation splits \n",
    "train_and_validation_ls = list()\n",
    "\n",
    "# Number of samples in training and validation cohorts \n",
    "nsamples_step2_ls_with_clin = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "military-retailer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:00.185367Z",
     "iopub.status.busy": "2023-01-26T10:55:00.184155Z",
     "iopub.status.idle": "2023-01-26T10:55:00.267543Z",
     "shell.execute_reply": "2023-01-26T10:55:00.265941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 485 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 486 cases out of 504 cases\"\n"
     ]
    }
   ],
   "source": [
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    # We will first combine the significant.features with the outcome variables\n",
    "    # Final list of features \n",
    "    feature.ls = c(paste0(end.point, c(\".clin\",\".time.clin\")), clin.var, significant.features.ls[[end.point]])\n",
    "   \n",
    "    if (is.null(significant.features.ls[[end.point]]) == F) {\n",
    "    \n",
    "        # Now we split the dataset into training and validation cohorts exactly as before.\n",
    "        train_and_validation = splitCases(data = tcga.dataset, \n",
    "                                  split = 0.75, \n",
    "                                  only.complete = T,\n",
    "                                  variables = feature.ls,\n",
    "                                  seed = 42)\n",
    "    \n",
    "        # Store \n",
    "        train_and_validation_ls[[end.point]] = train_and_validation   \n",
    "        nsamples.step2 = c(nrow(train_and_validation$train), \n",
    "                           nrow(train_and_validation$validation))\n",
    "    }    \n",
    "    else {\n",
    "    \n",
    "        # If there are now significant features store NULL\n",
    "        \n",
    "        # Store \n",
    "        train_and_validation_ls[[end.point]] = NULL\n",
    "        nsamples.step2 = c(NA, NA)\n",
    "    }\n",
    "        \n",
    "    names(nsamples.step2) = c(\"ntrain.step2\", \"nvalid.step2\")\n",
    "    nsamples_step2_ls_with_clin[[end.point]] = nsamples.step2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-source",
   "metadata": {},
   "source": [
    "## 5.3 Find the optimal lambda \n",
    "\n",
    "Use 10-fold cross-validation (CV) for the Cox model for different values of lamda. C-index will be use to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "violent-farmer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:00.272370Z",
     "iopub.status.busy": "2023-01-26T10:55:00.270944Z",
     "iopub.status.idle": "2023-01-26T10:55:00.286412Z",
     "shell.execute_reply": "2023-01-26T10:55:00.284937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store significant features \n",
    "rcox.res.with.clin.ls = list()\n",
    "\n",
    "# Store model matrices\n",
    "model.matrices.ls = list()\n",
    "\n",
    "# Store the fitted models for prediction \n",
    "pcox.fit.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "directed-darkness",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:00.290655Z",
     "iopub.status.busy": "2023-01-26T10:55:00.289400Z",
     "iopub.status.idle": "2023-01-26T10:55:03.516040Z",
     "shell.execute_reply": "2023-01-26T10:55:03.513676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    # Check the number of features\n",
    "    # Regulariation cannot be run if there is only one feature\n",
    "    num.feat = ncol(train_and_validation_ls[[end.point]]$train) - 2\n",
    "    \n",
    "    if (is.null(train_and_validation_ls[[end.point]]$train) == F){\n",
    "        if (num.feat > 1) {\n",
    "    \n",
    "            # Genereate model matrix \n",
    "            model.matrices = generateModelMatrices(train_and_validation_ls[[end.point]]$train, \n",
    "                             train_and_validation_ls[[end.point]]$validation, \n",
    "                             clinical.endpoint = end.point)\n",
    "        \n",
    "            model.matrices.ls[[end.point]] = model.matrices\n",
    "    \n",
    "            # Create output dir \n",
    "            dir.create(file.path(dir.res.pcox, end.point))\n",
    "    \n",
    "            # Find optimal lambda (hyperparameter for elastic net)\n",
    "            pcox.fit = findOptimalLambda(x = model.matrices$x.train.mat, \n",
    "                             y = model.matrices$y.train,\n",
    "                             out.dir = file.path(dir.res.pcox, end.point))\n",
    "        \n",
    "            pcox.fit.ls[[end.point]] = pcox.fit\n",
    "    \n",
    "            # Write the final features included in the model to a file \n",
    "            WriteXLS(pcox.fit$active.k.vals, \n",
    "             file.path(dir.res.pcox, end.point ,\"Active_covariates_in_lambda.min_model.xlsx\"), \n",
    "             BoldHeaderRow = T,\n",
    "             row.names = T)\n",
    "    \n",
    "            # Final significant features \n",
    "            rcox.res.with.clin = pcox.fit$active.k.vals %>% tibble::rownames_to_column(\"Feature\")\n",
    "            rcox.res.with.clin.ls[[end.point]] = rcox.res.with.clin  \n",
    "            \n",
    "        } else {\n",
    "            # If no significant features from earlier steps for the clin. end point then store null\n",
    "            model.matrices.ls[[end.point]] = NULL\n",
    "            pcox.fit.ls[[end.point]] = NULL\n",
    "            rcox.res.with.clin.ls[[end.point]] = NULL\n",
    "        }\n",
    "\n",
    "    } else {\n",
    "        # If no significant features from earlier steps for the clin. end point then store null\n",
    "        model.matrices.ls[[end.point]] = NULL\n",
    "        pcox.fit.ls[[end.point]] = NULL\n",
    "        rcox.res.with.clin.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-jonathan",
   "metadata": {},
   "source": [
    "## 5.4 Make predictions using the cross-validated model\n",
    "\n",
    "## 5.4.1 Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "legitimate-seattle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:03.521567Z",
     "iopub.status.busy": "2023-01-26T10:55:03.519955Z",
     "iopub.status.idle": "2023-01-26T10:55:03.538573Z",
     "shell.execute_reply": "2023-01-26T10:55:03.536773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.train.by.risk.ls = list()\n",
    "C.index.train.ls = list()\n",
    "AUC.train.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "compliant-western",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:03.543505Z",
     "iopub.status.busy": "2023-01-26T10:55:03.541984Z",
     "iopub.status.idle": "2023-01-26T10:55:03.554765Z",
     "shell.execute_reply": "2023-01-26T10:55:03.553068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for fixing variable names \n",
    "fixVarNames = function(x){\n",
    "    if (str_detect(x, \"Gender\")) {\n",
    "        return(\"Gender\")\n",
    "    } else if (str_detect(x, \"Tumor.stage\")){\n",
    "        return(\"Tumor.stage\")\n",
    "    } else if (str_detect(x,\".cn\")){\n",
    "        return(str_extract(x, \"\\\\w+.cn\"))\n",
    "    } else if (str_detect(x, \"Gleason.group\")){ \n",
    "        return(\"Gleason.group\")\n",
    "    } else {\n",
    "        return(x)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "essential-country",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:03.559539Z",
     "iopub.status.busy": "2023-01-26T10:55:03.558050Z",
     "iopub.status.idle": "2023-01-26T10:55:03.570904Z",
     "shell.execute_reply": "2023-01-26T10:55:03.569176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "calcAUC = function(pred.time, time, status, risk.score){\n",
    "    \n",
    "    # Calculate ROC characteristics\n",
    "    res.ROC = survivalROC(Stime = time,\n",
    "                          status = status,\n",
    "                          marker = risk.score,\n",
    "                          predict.time = pred.time,\n",
    "                          method  = \"KM\")\n",
    "    return(min(res.ROC$AUC,1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "spread-operation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:03.575743Z",
     "iopub.status.busy": "2023-01-26T10:55:03.574246Z",
     "iopub.status.idle": "2023-01-26T10:55:09.009879Z",
     "shell.execute_reply": "2023-01-26T10:55:09.008257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed \n",
    "set.seed(42)\n",
    "\n",
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    if (!is.null(pcox.fit.ls[[end.point]])) {\n",
    "    \n",
    "        # Predictions for the training set\n",
    "        pred.train <- predict(pcox.fit.ls[[end.point]]$model, \n",
    "                      newx = model.matrices.ls[[end.point]]$x.train.mat, \n",
    "                      s = \"lambda.min\", \n",
    "                      type = \"response\")\n",
    "\n",
    "        # Fitted relative risk\n",
    "        rel.risk <- pred.train[,1] \n",
    "        \n",
    "        # Calculate the C-index (NEW ADDITION )\n",
    "        c.index.train = Cindex(pred = pred.train, y = model.matrices.ls[[end.point]]$y.train) \n",
    "        C.index.train.ls[[end.point]] = c.index.train \n",
    "\n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- as.data.frame(as.matrix(model.matrices.ls[[end.point]]$y.train))\n",
    "        \n",
    "        \n",
    "        # TEST new function for calculating the C-index\n",
    "        cindex.train = concordance.index(rel.risk, \n",
    "                                         y.data$time, \n",
    "                                         y.data$status,\n",
    "                                         na.rm = TRUE)\n",
    "        \n",
    "        C.index.train.ls[[end.point]] = data.frame(\"C-index\" = round(cindex.train$c.index, 4),\n",
    "                                          \"C-index CI\" = paste0(\"(\", round(cindex.train$lower, 4), \" - \",  \n",
    "                                                                round(cindex.train$upper, 4), \")\"),\n",
    "                                        check.names = F)\n",
    "        \n",
    "\n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.train.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                        rel.risk = rel.risk)\n",
    "        \n",
    "        \n",
    "        # Calculate AUCs \n",
    "        auc.vect = round(map_dbl(c(365, 3 * 365, 5 * 365), .f = calcAUC, \n",
    "                   time = y.data$time, status = y.data$status , risk.score = rel.risk), 4)\n",
    "        names(auc.vect) = c(\"AUC (1y)\", \"AUC (3y)\", \"AUC (5y)\")\n",
    "        \n",
    "        AUC.train.ls[[end.point]] = as.data.frame(t(data.frame(auc.vect)))\n",
    "    \n",
    "        if (!is.null(KM.train.by.risk)) {\n",
    "        \n",
    "            # Store\n",
    "            KM.train.by.risk.ls[[end.point]] =  KM.train.by.risk$table\n",
    "    \n",
    "            # Store the KM plot\n",
    "            pdf(file.path(dir.res.pcox, end.point ,\"glmnet_K-M_plot_with_training_data.pdf\"), \n",
    "                width = 15, height = 12, onefile = F)\n",
    "            print(KM.train.by.risk$Plot)\n",
    "            dev.off()\n",
    "    \n",
    "            # Heatmap preparation \n",
    "    \n",
    "            # Variables to be selected \n",
    "            # Because Gender has been changed to a dummy variable its name has been changed\n",
    "            variables.selected = map_chr(rcox.res.with.clin.ls[[end.point]]$Feature, fixVarNames)\n",
    "    \n",
    "            # Get all input variables\n",
    "            heatmap.input.train = model.matrices.ls[[end.point]]$x.train %>% dplyr::select(all_of(variables.selected))\n",
    "    \n",
    "            # Heatmap of training data predictions\n",
    "            hmap.train <- prepareHeatmap(heatmap.input.train, y.data, pred.train, file.path(dir.res.pcox, end.point), \"glmnet_training\", row.height = 8)\n",
    "            \n",
    "        } else {\n",
    "            KM.train.by.risk.ls[[end.point]] = NULL\n",
    "            C.index.train.ls[[end.point]] = NULL\n",
    "            AUC.train.ls[[end.point]] = NULL\n",
    "            \n",
    "        }\n",
    "    } else {\n",
    "        KM.train.by.risk.ls[[end.point]] = NULL\n",
    "        C.index.train.ls[[end.point]] = NULL\n",
    "        AUC.train.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-metabolism",
   "metadata": {},
   "source": [
    "## 5.4.2 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "technological-concentration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:09.014454Z",
     "iopub.status.busy": "2023-01-26T10:55:09.013191Z",
     "iopub.status.idle": "2023-01-26T10:55:09.027142Z",
     "shell.execute_reply": "2023-01-26T10:55:09.025653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.valid.by.risk.ls = list()\n",
    "C.index.valid.ls = list()\n",
    "AUC.valid.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "orange-kazakhstan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:09.031409Z",
     "iopub.status.busy": "2023-01-26T10:55:09.030174Z",
     "iopub.status.idle": "2023-01-26T10:55:11.320143Z",
     "shell.execute_reply": "2023-01-26T10:55:11.317958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "set.seed(42)\n",
    "\n",
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    if (!is.null(pcox.fit.ls[[end.point]])) {\n",
    "    \n",
    "        # Predictions for the validation set\n",
    "        pred.valid <- predict(pcox.fit.ls[[end.point]]$model, \n",
    "                      newx = model.matrices.ls[[end.point]]$x.valid.mat, \n",
    "                      s = \"lambda.min\", \n",
    "                      type = \"response\")\n",
    "\n",
    "        # Fitted relative risk\n",
    "        rel.risk <- pred.valid[,1] \n",
    "\n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- as.data.frame(as.matrix(model.matrices.ls[[end.point]]$y.valid))\n",
    "        \n",
    "        \n",
    "        # TEST new function for calculating the C-index\n",
    "        cindex.valid = concordance.index(rel.risk, \n",
    "                                         y.data$time, \n",
    "                                         y.data$status,\n",
    "                                         na.rm = TRUE)\n",
    "        \n",
    "        C.index.valid.ls[[end.point]] = data.frame(\"C-index\" = round(cindex.valid$c.index, 4),\n",
    "                                          \"C-index CI\" = paste0(\"(\", round(cindex.valid$lower, 4), \" - \",  \n",
    "                                                                round(cindex.valid$upper, 4), \")\"),\n",
    "                                        check.names = F)\n",
    "        \n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.valid.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                        rel.risk = rel.risk)\n",
    "        \n",
    "        # Calculate AUCs \n",
    "        auc.vect = round(map_dbl(c(365, 3 * 365, 5 * 365), .f = calcAUC, \n",
    "                   time = y.data$time, status = y.data$status , risk.score = rel.risk),4)\n",
    "        \n",
    "        names(auc.vect) = c(\"AUC (1y)\", \"AUC (3y)\", \"AUC (5y)\")\n",
    "        \n",
    "        AUC.valid.ls[[end.point]] = as.data.frame(t(data.frame(auc.vect)))\n",
    "    \n",
    "        if (!is.null(KM.train.by.risk)) {\n",
    "            \n",
    "            # Store\n",
    "            KM.valid.by.risk.ls[[end.point]] =  KM.valid.by.risk$table\n",
    "    \n",
    "            # Store the KM plot\n",
    "            pdf(file.path(dir.res.pcox, end.point ,\"glmnet_K-M_plot_with_validation_data.pdf\"), \n",
    "                width = 15, height = 12, onefile = F)\n",
    "            print(KM.valid.by.risk$Plot)\n",
    "            dev.off()\n",
    "    \n",
    "            # Heatmap preparation \n",
    "    \n",
    "            # Variables to be selected \n",
    "            variables.selected = map_chr(rcox.res.with.clin.ls[[end.point]]$Feature, fixVarNames)\n",
    "    \n",
    "            # Get all input variables\n",
    "            heatmap.input.valid = model.matrices.ls[[end.point]]$x.valid %>% dplyr::select(all_of(variables.selected))\n",
    "    \n",
    "            # Heatmap of training data predictions\n",
    "            hmap.valid <- prepareHeatmap(heatmap.input.valid, y.data, pred.valid, file.path(dir.res.pcox, end.point), \"glmnet_validation\", row.height = 8)\n",
    "            \n",
    "        } else {\n",
    "            KM.valid.by.risk.ls[[end.point]] = NULL\n",
    "            C.index.valid.ls[[end.point]] = NULL\n",
    "            AUC.valid.ls[[end.point]] = NULL\n",
    "        }\n",
    "    } else {\n",
    "        KM.valid.by.risk.ls[[end.point]] = NULL\n",
    "        C.index.valid.ls[[end.point]] = NULL\n",
    "        AUC.valid.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "linear-shame",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.324982Z",
     "iopub.status.busy": "2023-01-26T10:55:11.323614Z",
     "iopub.status.idle": "2023-01-26T10:55:11.346798Z",
     "shell.execute_reply": "2023-01-26T10:55:11.345290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect the results into a single data frame\n",
    "\n",
    "# Log-rank test results \n",
    "KM.by.risk.with.clin.train = bind_rows(KM.train.by.risk.ls, .id = \"End point\")\n",
    "KM.by.risk.with.clin.valid = bind_rows(KM.valid.by.risk.ls, .id = \"End point\")\n",
    "\n",
    "# C-indices\n",
    "C.index.train.df = bind_rows(C.index.train.ls , .id = \"End point\")\n",
    "C.index.valid.df = bind_rows(C.index.valid.ls , .id = \"End point\")\n",
    "\n",
    "# AUCs \n",
    "auc.train.df = bind_rows(AUC.train.ls, .id  = \"End point\") \n",
    "auc.valid.df = bind_rows(AUC.valid.ls, .id  = \"End point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "disabled-characteristic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.351569Z",
     "iopub.status.busy": "2023-01-26T10:55:11.350063Z",
     "iopub.status.idle": "2023-01-26T10:55:11.372676Z",
     "shell.execute_reply": "2023-01-26T10:55:11.371196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store final resilts\n",
    "write.csv(KM.by.risk.with.clin.train, file.path(dir.res.pcox, \"Final_evaluation_results_training.csv\"), row.names = F)\n",
    "write.csv(KM.by.risk.with.clin.valid, file.path(dir.res.pcox, \"Final_evaluation_results_validation.csv\"),row.names = F)\n",
    "\n",
    "write.csv(C.index.train.df, file.path(dir.res.pcox, \"Final_evaluation_C_index_training.csv\"), row.names = F)\n",
    "write.csv(C.index.valid.df, file.path(dir.res.pcox, \"Final_evaluation_C_index_validation.csv\"), row.names = F)\n",
    "\n",
    "write.csv(auc.train.df, file.path(dir.res.pcox, \"Final_evaluation_AUC_training.csv\"), row.names = F)\n",
    "write.csv(auc.valid.df, file.path(dir.res.pcox, \"Final_evaluation_AUC_validation.csv\"), row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-probe",
   "metadata": {},
   "source": [
    "# 6. For each clinical end point produce a reference model including only clinical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "numeric-disease",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.377065Z",
     "iopub.status.busy": "2023-01-26T10:55:11.375742Z",
     "iopub.status.idle": "2023-01-26T10:55:11.387885Z",
     "shell.execute_reply": "2023-01-26T10:55:11.386368Z"
    }
   },
   "outputs": [],
   "source": [
    "dir.res.pcox = file.path(dir.res.root, \"Penalized_Cox_risk_prediction/customer_features/Only_clinical_features\")\n",
    "dir.create(dir.res.pcox, recursive = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-turkey",
   "metadata": {},
   "source": [
    "## 6.1 Splitting dataset into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "systematic-township",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.392243Z",
     "iopub.status.busy": "2023-01-26T10:55:11.390943Z",
     "iopub.status.idle": "2023-01-26T10:55:11.402068Z",
     "shell.execute_reply": "2023-01-26T10:55:11.400537Z"
    }
   },
   "outputs": [],
   "source": [
    "# x : training_and_validation data \n",
    "# rm : Keep the listed variables\n",
    "dropFeatures = function(x, rm){\n",
    "    x$train = dplyr::select(x$train, -all_of(rm))\n",
    "    x$validation = dplyr::select(x$validation, -all_of(rm))\n",
    "    return(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "announced-casino",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.423098Z",
     "iopub.status.busy": "2023-01-26T10:55:11.421746Z",
     "iopub.status.idle": "2023-01-26T10:55:11.433783Z",
     "shell.execute_reply": "2023-01-26T10:55:11.431931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we store all the training and validation splits \n",
    "train_and_validation_ref_ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "rapid-pierce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.438822Z",
     "iopub.status.busy": "2023-01-26T10:55:11.437205Z",
     "iopub.status.idle": "2023-01-26T10:55:11.580865Z",
     "shell.execute_reply": "2023-01-26T10:55:11.579304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 485 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 436 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 295 cases out of 504 cases\"\n",
      "[1] \"Taking only complete cases\"\n",
      "[1] \"Including 486 cases out of 504 cases\"\n"
     ]
    }
   ],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "\n",
    "    # We will first combine the significant.features with the outcome variables\n",
    "    # Final list of features \n",
    "    feature.ls = c(paste0(end.point, c(\".clin\",\".time.clin\")), clin.var, significant.features.ls[[end.point]])\n",
    "    \n",
    "    # Now we split the dataset into training and validation cohorts exactly as before.\n",
    "    train_and_validation.only.clin = splitCases(data = tcga.dataset, \n",
    "                                  split = 0.75, \n",
    "                                  only.complete = T,\n",
    "                                  variables = feature.ls,\n",
    "                                  seed = 42)\n",
    "    \n",
    "    # Remove gene-based features \n",
    "    train_and_validation_ref_ls[[end.point]] = dropFeatures(train_and_validation.only.clin, significant.features.ls[[end.point]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-immune",
   "metadata": {},
   "source": [
    "For simplicity and to ensure that we will have a reference model we will apply conventional cox regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-socket",
   "metadata": {},
   "source": [
    "## 6.2 Fit the model and check the proportionality assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "whole-honey",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.585667Z",
     "iopub.status.busy": "2023-01-26T10:55:11.584306Z",
     "iopub.status.idle": "2023-01-26T10:55:11.595348Z",
     "shell.execute_reply": "2023-01-26T10:55:11.593973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store COX models\n",
    "pcox.ref.fit.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "divided-comparison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.599456Z",
     "iopub.status.busy": "2023-01-26T10:55:11.598257Z",
     "iopub.status.idle": "2023-01-26T10:55:11.608819Z",
     "shell.execute_reply": "2023-01-26T10:55:11.607436Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Function fits a cox regression model\n",
    "# \n",
    "fitCoxModel = function(data, end.point, features){\n",
    "    \n",
    "    # Expand to variable name\n",
    "    end_point_time = paste0(end.point, \".time.clin\")\n",
    "    end_point_event = paste0(end.point, \".clin\")\n",
    "\n",
    "    # Generate a survival formula object \n",
    "    survExpression = paste0(\"Surv(\", end_point_time, \", \" , end_point_event, \")\")\n",
    "    f <- as.formula(paste(survExpression, paste(features, collapse = \" + \"), sep = \" ~ \"))\n",
    "    \n",
    "    model.fit = coxph(f, data = data)\n",
    "    return(model.fit)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "straight-presence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.612800Z",
     "iopub.status.busy": "2023-01-26T10:55:11.611606Z",
     "iopub.status.idle": "2023-01-26T10:55:11.674621Z",
     "shell.execute_reply": "2023-01-26T10:55:11.673254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             OS.clin OS.time.clin   Age Gender Tumor.stage\n",
      "TCGA-85-8352       1          161 24788   male     Stage 3\n",
      "TCGA-46-3766       0          370 22707 female     Stage 1\n",
      "TCGA-98-A53B       1           61 25390   male     Stage 1\n",
      "TCGA-22-1011       1           53 26732   male     Stage 1\n",
      "TCGA-43-A474       0          353 24286   male     Stage 2\n",
      "TCGA-77-6845       1          708 25321   male     Stage 2\n",
      "             DSS.clin DSS.time.clin   Age Gender Tumor.stage\n",
      "TCGA-60-2706        0          2820 21477   male     Stage 1\n",
      "TCGA-66-2785        0            60 23772   male     Stage 1\n",
      "TCGA-58-8393        0          1058 25132 female     Stage 1\n",
      "TCGA-85-7844        0           911 26141   male     Stage 1\n",
      "TCGA-22-5474        0           445 27271   male     Stage 1\n",
      "TCGA-O2-A52V        0          1335 27449 female     Stage 2\n",
      "             DFI.clin DFI.time.clin   Age Gender Tumor.stage\n",
      "TCGA-34-2605        1           394 27833   male     Stage 3\n",
      "TCGA-56-8305        0           105 26428   male     Stage 1\n",
      "TCGA-43-3920        0          1007 26059   male     Stage 1\n",
      "TCGA-56-6545        0           666 28400 female     Stage 1\n",
      "TCGA-34-5234        0          2271 26072 female     Stage 1\n",
      "TCGA-39-5021        1          1875 25895   male     Stage 1\n",
      "             PFI.clin PFI.time.clin   Age Gender Tumor.stage\n",
      "TCGA-85-8352        1           128 24788   male     Stage 3\n",
      "TCGA-85-A50M        0           826 17429   male     Stage 2\n",
      "TCGA-85-A513        0           910 21967 female     Stage 1\n",
      "TCGA-NC-A5HM        0          1212 27938   male     Stage 1\n",
      "TCGA-22-1011        0            53 26732   male     Stage 1\n",
      "TCGA-34-5234        0          2271 26072 female     Stage 1\n"
     ]
    }
   ],
   "source": [
    "# Fit the models\n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    print(head(train_and_validation_ref_ls[[end.point]]$train))\n",
    "    if (nrow(train_and_validation_ref_ls[[end.point]]$train) > 1) {\n",
    "        pcox.ref.fit.ls[[end.point]] = fitCoxModel(train_and_validation_ref_ls[[end.point]]$train, end.point, clin.var)\n",
    "    } else {\n",
    "        pcox.ref.fit.ls[[end.point]] = NULL\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-scotland",
   "metadata": {},
   "source": [
    "## 6.3 Make predictions with the full model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-opportunity",
   "metadata": {},
   "source": [
    "### 6.3.1 Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "hourly-rendering",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.678862Z",
     "iopub.status.busy": "2023-01-26T10:55:11.677657Z",
     "iopub.status.idle": "2023-01-26T10:55:11.690719Z",
     "shell.execute_reply": "2023-01-26T10:55:11.689353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.train.ref.by.risk.ls = list()\n",
    "C.index.ref.train.ls = list()\n",
    "AUC.train.ref.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "hungry-candle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:11.694764Z",
     "iopub.status.busy": "2023-01-26T10:55:11.693552Z",
     "iopub.status.idle": "2023-01-26T10:55:15.842514Z",
     "shell.execute_reply": "2023-01-26T10:55:15.840600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    if (is.null(pcox.ref.fit.ls[[end.point]]) != T) {\n",
    "    \n",
    "        # Apply model to predict the risk scores \n",
    "        rel.risk = predict(object = pcox.ref.fit.ls[[end.point]], \n",
    "               newdata = train_and_validation_ref_ls[[end.point]]$train[,clin.var, drop = F], \n",
    "               type = \"risk\")\n",
    "\n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- train_and_validation_ref_ls[[end.point]]$train[paste0(end.point, c(\".clin\",\".time.clin\"))]\n",
    "        colnames(y.data) = c(\"status\",\"time\")\n",
    "    \n",
    "    \n",
    "        # TEST new function for calculating the C-index\n",
    "        cindex.ref.train = concordance.index(rel.risk, \n",
    "                                         y.data$time, \n",
    "                                         y.data$status,\n",
    "                                         na.rm = TRUE)\n",
    "        \n",
    "        C.index.ref.train.ls[[end.point]] = data.frame(\"C-index\" = round(cindex.ref.train$c.index, 4),\n",
    "                                   \"C-index CI\" = paste0(\"(\", round(cindex.ref.train$lower, 4), \" - \",  \n",
    "                                                         round(cindex.ref.train$upper, 4), \")\"), check.names = F)\n",
    "    \n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.train.ref.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                                                rel.risk = rel.risk)\n",
    "    \n",
    "        KM.train.ref.by.risk.ls[[end.point]] =  KM.train.ref.by.risk$table\n",
    "    \n",
    "        # Calculate AUCs \n",
    "        auc.vect = round(map_dbl(c(365, 3 * 365, 5 * 365), .f = calcAUC, \n",
    "                   time = y.data$time, status = y.data$status , risk.score = rel.risk),4)\n",
    "        \n",
    "        names(auc.vect) = c(\"AUC (1y)\", \"AUC (3y)\", \"AUC (5y)\")\n",
    "        \n",
    "        AUC.train.ref.ls[[end.point]] = as.data.frame(t(data.frame(auc.vect)))  \n",
    "    \n",
    "    } else {\n",
    "        \n",
    "        KM.train.ref.by.risk.ls[[end.point]] = NULL\n",
    "        C.index.ref.train.ls[[end.point]] = NULL\n",
    "        AUC.train.ref.ls[[end.point]] = NULL\n",
    "        \n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-revelation",
   "metadata": {},
   "source": [
    "### 6.3.2 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "local-freight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:15.847463Z",
     "iopub.status.busy": "2023-01-26T10:55:15.846063Z",
     "iopub.status.idle": "2023-01-26T10:55:15.862427Z",
     "shell.execute_reply": "2023-01-26T10:55:15.860125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the result tables\n",
    "KM.valid.ref.by.risk.ls = list()\n",
    "C.index.ref.valid.ls = list()\n",
    "AUC.valid.ref.ls = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "boolean-arbitration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:15.868176Z",
     "iopub.status.busy": "2023-01-26T10:55:15.866246Z",
     "iopub.status.idle": "2023-01-26T10:55:16.909389Z",
     "shell.execute_reply": "2023-01-26T10:55:16.907652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over end points \n",
    "for (end.point in c(\"OS\",\"DSS\",\"DFI\",\"PFI\")){\n",
    "    \n",
    "    \n",
    "    if (is.null(pcox.ref.fit.ls[[end.point]]) != T) {\n",
    "    \n",
    "        # Apply model to predict the risk scores \n",
    "        rel.risk = predict(object = pcox.ref.fit.ls[[end.point]], \n",
    "               newdata = train_and_validation_ref_ls[[end.point]]$validation[,clin.var, drop = F], \n",
    "               type = \"risk\")\n",
    "    \n",
    "        # Stratify validation data into two groups based on the fitted relative risk\n",
    "        y.data <- train_and_validation_ref_ls[[end.point]]$validation[paste0(end.point, c(\".clin\",\".time.clin\"))]\n",
    "        colnames(y.data) = c(\"status\",\"time\")\n",
    "    \n",
    "    \n",
    "        # TEST new function for calculating the C-index\n",
    "        cindex.ref.valid = concordance.index(rel.risk, \n",
    "                                         y.data$time, \n",
    "                                         y.data$status,\n",
    "                                         na.rm = TRUE)\n",
    "        \n",
    "        C.index.ref.valid.ls[[end.point]] = data.frame(\"C-index\" = round(cindex.ref.valid$c.index, 4),\n",
    "                                                   \"C-index CI\" = paste0(\"(\", round(cindex.ref.valid$lower, 4), \" - \",  \n",
    "                                                         round(cindex.ref.valid$upper, 4), \")\"), check.names = F)\n",
    "    \n",
    "        # Plot KM and extract the p-value  \n",
    "        KM.valid.ref.by.risk = plotKMbyRelativeRisk(data = y.data, \n",
    "                                                rel.risk = rel.risk)\n",
    "    \n",
    "        KM.valid.ref.by.risk.ls[[end.point]] =  KM.valid.ref.by.risk$table\n",
    "    \n",
    "    \n",
    "        # Calculate AUCs \n",
    "        auc.vect = round(map_dbl(c(365, 3 * 365, 5 * 365), .f = calcAUC, \n",
    "                   time = y.data$time, status = y.data$status , risk.score = rel.risk),4)\n",
    "        \n",
    "        names(auc.vect) = c(\"AUC (1y)\", \"AUC (3y)\", \"AUC (5y)\")\n",
    "        \n",
    "        AUC.valid.ref.ls[[end.point]] = as.data.frame(t(data.frame(auc.vect)))\n",
    "        \n",
    "    } else {\n",
    "        \n",
    "        KM.valid.ref.by.risk.ls[[end.point]] = NULL\n",
    "        C.index.ref.valid.ls[[end.point]] = NULL\n",
    "        AUC.valid.ref.ls[[end.point]] = NULL\n",
    "    \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "committed-handle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:16.914100Z",
     "iopub.status.busy": "2023-01-26T10:55:16.912792Z",
     "iopub.status.idle": "2023-01-26T10:55:16.934997Z",
     "shell.execute_reply": "2023-01-26T10:55:16.933485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect the results into a single data frame\n",
    "\n",
    "# Log-rank test results \n",
    "KM.train.ref.by.risk.df = bind_rows(KM.train.ref.by.risk.ls, .id = \"End point\")\n",
    "KM.valid.ref.by.risk.df = bind_rows(KM.valid.ref.by.risk.ls, .id = \"End point\")\n",
    "\n",
    "# C-indices\n",
    "C.index.ref.train.df = bind_rows(C.index.ref.train.ls , .id = \"End point\")\n",
    "C.index.ref.valid.df = bind_rows(C.index.ref.valid.ls , .id = \"End point\")\n",
    "\n",
    "# AUCs \n",
    "auc.train.ref.df = bind_rows(AUC.train.ref.ls, .id  = \"End point\") \n",
    "auc.valid.ref.df = bind_rows(AUC.valid.ref.ls, .id  = \"End point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "narrow-reputation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:16.939317Z",
     "iopub.status.busy": "2023-01-26T10:55:16.938008Z",
     "iopub.status.idle": "2023-01-26T10:55:16.960069Z",
     "shell.execute_reply": "2023-01-26T10:55:16.958574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store final resilts\n",
    "write.csv(KM.train.ref.by.risk.df, file.path(dir.res.pcox, \"Final_evaluation_results_training.csv\"), row.names = F)\n",
    "write.csv(KM.valid.ref.by.risk.df, file.path(dir.res.pcox, \"Final_evaluation_results_validation.csv\"),row.names = F)\n",
    "\n",
    "write.csv(C.index.ref.train.df, file.path(dir.res.pcox, \"Final_evaluation_C_index_training.csv\"), row.names = F)\n",
    "write.csv(C.index.ref.valid.df, file.path(dir.res.pcox, \"Final_evaluation_C_index_validation.csv\"), row.names = F)\n",
    "\n",
    "write.csv(auc.train.ref.df, file.path(dir.res.pcox, \"Final_evaluation_AUC_training.csv\"), row.names = F)\n",
    "write.csv(auc.valid.ref.df, file.path(dir.res.pcox, \"Final_evaluation_AUC_validation.csv\"), row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-somerset",
   "metadata": {},
   "source": [
    "# 7. Collect the relevant results and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-duration",
   "metadata": {},
   "source": [
    "What statistics and results we want to collect :\n",
    "\n",
    "1. Number of samples in training and validation set (Feature selection step 1) = ntrain.step1, nvalid.step1\n",
    "2. Clinical end point statistics (Indicate final selected end point) = clinical.end.point.stats\n",
    "3. Summary statistics for features (Indicate selected features for first feature selection) = exp.summary.training, cn.summary.training\n",
    "4. Results after first feature selection step 1 = km.pvalue.table\n",
    "5. Number of samples in training and validation set without clinical features (Feature selection step 2) = ntrain_step2.no.clin, nvalid.step2.no.clin\n",
    "6. Results after second feature selection step without clinical features = rcox.res.no.clin\n",
    "7. Final evaluation results with KM without clinical features = KM.by.risk.no.clin \n",
    "8. Number of samples in training and validation set without clinical features (Feature selection step 2) = ntrain_step2.with.clin, nvalid.step2.with.clin\n",
    "9. Results after second feature selection step without clinical features = rcox.res.with.clin\n",
    "10. Final evaluation results with KM with clinical features = KM.by.risk.with.clin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "environmental-australian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:16.964615Z",
     "iopub.status.busy": "2023-01-26T10:55:16.963311Z",
     "iopub.status.idle": "2023-01-26T10:55:16.974315Z",
     "shell.execute_reply": "2023-01-26T10:55:16.972818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect into a list \n",
    "final.result.collection = list(\"FSS1_sample_summary\" = nsamples_step1_ls,\n",
    "                               \"Clinical_endpoint_stats\" = clinical.end.point.stats,\n",
    "                               \"Feature_summary_stats\" = summary.stats.ls,\n",
    "                               \"FSS1_results_summary\" = km.pvalue.table.ls,\n",
    "                               \"FSS2_sample_summary_no_clin\" = nsamples_step2_ls_no_clin,\n",
    "                               \"FSS2_regcox_res_no_clin\" = rcox.res.no.clin.ls,\n",
    "                               \"Final_res_KM_no_clin_train\" = KM.by.risk.no.clin.train,\n",
    "                               \"Final_res_KM_no_clin_valid\" = KM.by.risk.no.clin.valid,\n",
    "                               \"FSS2_sample_summary_with_clin\" = nsamples_step2_ls_with_clin,\n",
    "                               \"FSS2_regcox_res_with_clin\" = rcox.res.with.clin.ls,\n",
    "                               \"Final_res_KM_with_clin_train\" = KM.by.risk.with.clin.train,\n",
    "                               \"Final_res_KM_with_clin_valid\" = KM.by.risk.with.clin.valid,\n",
    "                               \"FSS2_sample_summary_only_clin\" = nsamples.step2,\n",
    "                               \"Final_res_KM_only_clin_train\" = KM.train.ref.by.risk.df,\n",
    "                               \"Final_res_KM_only_clin_valid\" = KM.valid.ref.by.risk.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "present-butterfly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:16.978525Z",
     "iopub.status.busy": "2023-01-26T10:55:16.977232Z",
     "iopub.status.idle": "2023-01-26T10:55:16.988550Z",
     "shell.execute_reply": "2023-01-26T10:55:16.987070Z"
    }
   },
   "outputs": [],
   "source": [
    "saveRDS(final.result.collection, file.path(dir.res.root, \"Final_results_collection.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-monroe",
   "metadata": {},
   "source": [
    "# Session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "excited-performance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:55:16.993052Z",
     "iopub.status.busy": "2023-01-26T10:55:16.991756Z",
     "iopub.status.idle": "2023-01-26T10:55:17.056607Z",
     "shell.execute_reply": "2023-01-26T10:55:17.054790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 4.1.3 (2022-03-10)\n",
       "Platform: x86_64-redhat-linux-gnu (64-bit)\n",
       "Running under: AlmaLinux 8.5 (Arctic Sphynx)\n",
       "\n",
       "Matrix products: default\n",
       "BLAS/LAPACK: /usr/lib64/libopenblas-r0.3.12.so\n",
       "\n",
       "locale:\n",
       " [1] LC_CTYPE=C.UTF-8           LC_NUMERIC=C              \n",
       " [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    \n",
       " [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   \n",
       " [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 \n",
       " [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n",
       "[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       \n",
       "\n",
       "attached base packages:\n",
       " [1] stats4    parallel  grid      stats     graphics  grDevices utils    \n",
       " [8] datasets  methods   base     \n",
       "\n",
       "other attached packages:\n",
       " [1] DESeq2_1.34.0               SummarizedExperiment_1.24.0\n",
       " [3] Biobase_2.54.0              MatrixGenerics_1.6.0       \n",
       " [5] matrixStats_0.62.0          GenomicRanges_1.46.1       \n",
       " [7] GenomeInfoDb_1.30.1         IRanges_2.28.0             \n",
       " [9] S4Vectors_0.32.4            BiocGenerics_0.40.0        \n",
       "[11] biomaRt_2.50.3              survivalROC_1.0.3          \n",
       "[13] survcomp_1.44.1             prodlim_2019.11.13         \n",
       "[15] broom_0.8.0                 ComplexHeatmap_2.10.0      \n",
       "[17] circlize_0.4.14             ggfortify_0.4.14           \n",
       "[19] WriteXLS_6.4.0              glmnet_4.1-4               \n",
       "[21] Matrix_1.5-3                survminer_0.4.9            \n",
       "[23] ggpubr_0.4.0                survival_3.3-1             \n",
       "[25] forcats_0.5.1               stringr_1.4.0              \n",
       "[27] dplyr_1.0.9                 purrr_0.3.4                \n",
       "[29] readr_2.1.2                 tidyr_1.2.0                \n",
       "[31] tibble_3.1.7                tidyverse_1.3.1            \n",
       "[33] ggplot2_3.3.5              \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       "  [1] readxl_1.4.0           uuid_1.1-0             backports_1.4.1       \n",
       "  [4] BiocFileCache_2.2.1    repr_1.1.4             splines_4.1.3         \n",
       "  [7] BiocParallel_1.28.3    listenv_0.8.0          digest_0.6.29         \n",
       " [10] SuppDists_1.1-9.7      foreach_1.5.2          htmltools_0.5.2       \n",
       " [13] magick_2.7.3           fansi_1.0.3            magrittr_2.0.3        \n",
       " [16] memoise_2.0.1          cluster_2.1.3          doParallel_1.0.17     \n",
       " [19] tzdb_0.3.0             annotate_1.72.0        globals_0.15.0        \n",
       " [22] Biostrings_2.62.0      modelr_0.1.8           prettyunits_1.1.1     \n",
       " [25] colorspace_2.0-3       rappdirs_0.3.3         blob_1.2.3            \n",
       " [28] rvest_1.0.2            haven_2.5.0            xfun_0.30             \n",
       " [31] crayon_1.5.1           RCurl_1.98-1.6         jsonlite_1.8.0        \n",
       " [34] genefilter_1.76.0      zoo_1.8-10             iterators_1.0.14      \n",
       " [37] glue_1.6.2             gtable_0.3.0           zlibbioc_1.40.0       \n",
       " [40] XVector_0.34.0         DelayedArray_0.20.0    GetoptLong_1.0.5      \n",
       " [43] car_3.0-12             future.apply_1.9.0     shape_1.4.6           \n",
       " [46] abind_1.4-5            scales_1.2.0           DBI_1.1.2             \n",
       " [49] rstatix_0.7.0          Rcpp_1.0.8.3           gridtext_0.1.4        \n",
       " [52] progress_1.2.2         xtable_1.8-4           clue_0.3-60           \n",
       " [55] bit_4.0.4              km.ci_0.5-6            lava_1.6.10           \n",
       " [58] httr_1.4.3             RColorBrewer_1.1-3     ellipsis_0.3.2        \n",
       " [61] farver_2.1.0           pkgconfig_2.0.3        XML_3.99-0.9          \n",
       " [64] dbplyr_2.1.1           locfit_1.5-9.5         utf8_1.2.2            \n",
       " [67] labeling_0.4.2         tidyselect_1.1.2       rlang_1.0.2           \n",
       " [70] AnnotationDbi_1.56.2   munsell_0.5.0          cellranger_1.1.0      \n",
       " [73] tools_4.1.3            cachem_1.0.6           cli_3.3.0             \n",
       " [76] generics_0.1.2         RSQLite_2.2.12         evaluate_0.15         \n",
       " [79] fastmap_1.1.0          bootstrap_2019.6       knitr_1.39            \n",
       " [82] bit64_4.0.5            fs_1.5.2               survMisc_0.5.6        \n",
       " [85] KEGGREST_1.34.0        future_1.26.1          xml2_1.3.3            \n",
       " [88] compiler_4.1.3         rstudioapi_0.13        filelock_1.0.2        \n",
       " [91] curl_4.3.2             png_0.1-7              ggsignif_0.6.3        \n",
       " [94] reprex_2.0.1           geneplotter_1.72.0     stringi_1.7.6         \n",
       " [97] lattice_0.20-45        IRdisplay_1.1          markdown_1.1          \n",
       "[100] KMsurv_0.1-5           vctrs_0.4.1            pillar_1.7.0          \n",
       "[103] lifecycle_1.0.1        GlobalOptions_0.1.2    data.table_1.14.2     \n",
       "[106] bitops_1.0-7           R6_2.5.1               KernSmooth_2.23-20    \n",
       "[109] gridExtra_2.3          parallelly_1.32.0      codetools_0.2-18      \n",
       "[112] assertthat_0.2.1       rjson_0.2.21           withr_2.5.0           \n",
       "[115] GenomeInfoDbData_1.2.7 ggtext_0.1.1           hms_1.1.1             \n",
       "[118] IRkernel_1.3           carData_3.0-5          pbdZMQ_0.3-7          \n",
       "[121] getPass_0.2-2          lubridate_1.8.0        base64enc_0.1-3       \n",
       "[124] rmeta_3.0             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionInfo()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R 4.1.3",
   "language": "R",
   "name": "r4.1.3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
